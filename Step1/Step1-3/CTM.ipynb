{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from konlpy.tag import Okt\n",
    "from bertopic import BERTopic  # Or use a different CTM library if preferred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the metadata\n",
    "metadata_file = \"C:\\\\Users\\\\WINDOWS11\\\\Desktop\\\\kpop_agenda\\\\Step1\\\\metadata_top300_filtered.tsv\"\n",
    "metadata_df = pd.read_csv(metadata_file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load the text data\n",
    "texts = []\n",
    "file_paths = metadata_df['file_path'].tolist()\n",
    "tokenizer = Okt()  # Initialize the tokenizer\n",
    "\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            # Tokenize the text using konlpy\n",
    "            tokens = tokenizer.morphs(text)  # Or use other suitable tokenization methods\n",
    "            texts.append(\" \".join(tokens))  # Join tokens back into a string for BERTopic\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        texts.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train the BERTopic model\n",
    "topic_model = BERTopic(language=\"korean\")  # Or specify language=\"korean\" if primarily Korean\n",
    "topics, probabilities = topic_model.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Get the dominant topic for each document\n",
    "dominant_topics = [topic_model.get_topic_info().iloc[topic]['Name'] for topic in topics]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Add the topic information to the DataFrame\n",
    "metadata_df['topic_type'] = dominant_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Save the updated DataFrame\n",
    "output_file = \"C:/Users/WINDOWS11/Desktop/kpop_agenda/Step1/metadata_top300_with_topics.tsv\"\n",
    "metadata_df.to_csv(output_file, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. (Optional) Explore topics\n",
    "topic_model.visualize_topics()\n",
    "# Or print topic information\n",
    "for i in range(len(dominant_topics)):\n",
    "    print(f\"Article: {metadata_df['title'][i]}\\nTopic: {dominant_topics[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
